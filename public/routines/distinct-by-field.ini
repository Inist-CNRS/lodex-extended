;
; Exemple d'appel :
;   - /api/run/distinct-by-field/i31i/
;
prepend = delegate?file=../worker.ini
mimeType = application/json
label = distinct-by-field

[use]
plugin = analytics
plugin = lodex

; On garde dans l'environnement quelques paramètres
[env?single]
path = total
value = get('total').parseInt().defaultTo(0)

path = minValue
value = env('minValue').parseInt().defaultTo(0)

path = maxValue
value = env('maxValue').parseInt().defaultTo(1000000)

path = maxSize
value = env('maxSize').parseInt().defaultTo(10)

path = reverse
value = env('orderBy').split('/').get(1).replace('asc', 0).replace('desc', 1).parseInt()

path = tuneBy
value = env('orderBy').split('/').get(0).replace('_id', 'id')

; On récupére les documents filtrés
[LodexRunQuery]

; On supprime les infos inutiles
[filterVersions]
[filterContributions]

; on explose le flux en fonction des champs source et target
[distinct]
path = env('field.0')

; on regroupe par champ identique
[reducing]

; on compte le nombre de valeur regroupée pour chaque champ identique
[summing]

; On filtre les valeurs minimales
[greater]
than = env('minValue')

; On filtre les valeurs minimales
[less]
than = env('maxValue')

; On calcul un score pour permettre le tri
[tune]
path = env('tuneBy', 'value')

; On tri
[sort]
reverse = env('reverse')

; On garde uniqument les valeurs (donc on supprime les informations qui ont permis le tri)
[value]

; On envoit au client uniquement les premiers documents
[slice]
start = 1
size = env('maxSize')

; On prépare le json de sortie
[replace]
path = _id
value = get('id')

path = value
value = get('value')

path = total
value = env('total')

path = maxSize
value = env('maxSize')

path = minValue
value = env('minValue')

path = maxValue
value = env('maxValue')

# On génére le json de sortie
[LodexOutput]
indent = true
extract = total
extract = maxSize
extract = maxValue
extract = minValue
